{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing training data to see scattered data to get intusion what kind of classifier paramter could fit best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from prep_terrain_data import makeTerrainData\n",
    "from class_vis import prettyPicture\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "### the training data (features_train, labels_train) have both \"fast\" and \"slow\"\n",
    "### points mixed together--separate them so we can give them different colors\n",
    "### in the scatterplot and identify them visually\n",
    "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "grade_fast_test = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_train[ii]==0]\n",
    "bumpy_fast_test = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_train[ii]==0]\n",
    "grade_slow_test = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_train[ii]==1]\n",
    "bumpy_slow_test = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_train[ii]==1]\n",
    "\n",
    "#### initial visualization\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.scatter(bumpy_fast, grade_fast, color = \"r\", label=\"fast\")\n",
    "plt.scatter(grade_slow, bumpy_slow, color = \"b\", label=\"slow\")\n",
    "plt.scatter(bumpy_fast_test, grade_fast_test, color = \"k\", label=\"test data\")\n",
    "plt.scatter(grade_slow_test, bumpy_slow_test, color = \"k\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"bumpiness\")\n",
    "plt.ylabel(\"grade\")\n",
    "plt.show()\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising two array to store classifier name and its accuracy to finaly visualise the results \n",
    "classifier_name=[]\n",
    "classifier_accuracy=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Support Vector Machine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=KNeighborsClassifier(n_neighbors=4)\n",
    "clf.fit(features_train, labels_train)\n",
    "clfName='KNN'\n",
    "pred=clf.predict(features_test)\n",
    "print 'Accuracy Score:',accuracy_score(labels_test,pred)\n",
    "classifier_name.append(clfName)\n",
    "classifier_accuracy.append(accuracy_score(labels_test,pred))\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf=SVC(kernel='linear')\n",
    "clf.fit(features_train, labels_train)\n",
    "pred=clf.predict(features_test)\n",
    "print 'Accuracy Score:',accuracy_score(labels_test,pred)\n",
    "clfName='SVM'\n",
    "classifier_name.append(clfName)\n",
    "classifier_accuracy.append(accuracy_score(labels_test,pred))\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf=tree.DecisionTreeClassifier(min_samples_split=60)\n",
    "clf.fit(features_train, labels_train)\n",
    "pred=clf.predict(features_test)\n",
    "print 'Accuracy Score:',accuracy_score(labels_test,pred)\n",
    "clfName='Decision Tree'\n",
    "classifier_name.append(clfName)\n",
    "classifier_accuracy.append(accuracy_score(labels_test,pred))\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf=GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "pred=clf.predict(features_test)\n",
    "print 'Accuracy Score:',accuracy_score(labels_test,pred)\n",
    "clfName='Naive Bayes'\n",
    "classifier_name.append(clfName)\n",
    "classifier_accuracy.append(accuracy_score(labels_test,pred))\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf.fit(features_train, labels_train)\n",
    "pred=clf.predict(features_test)\n",
    "scores = cross_val_score(clf, features_train,labels_train)\n",
    "#print(scores.mean())\n",
    "print 'Accuracy Score:',accuracy_score(labels_test,pred)\n",
    "clfName='Decision Tree'\n",
    "classifier_name.append(clfName)\n",
    "classifier_accuracy.append(accuracy_score(labels_test,pred))\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(features_train, labels_train)\n",
    "pred=clf.predict(features_test)\n",
    "print 'Accuracy Score:',accuracy_score(labels_test,pred)\n",
    "clfName='Random Forest'\n",
    "classifier_name.append(clfName)\n",
    "classifier_accuracy.append(accuracy_score(labels_test,pred))\n",
    "try:\n",
    "    prettyPicture(clf, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "====================\n",
    "Horizontal bar chart\n",
    "====================\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcdefaults()\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Example data\n",
    "name = classifier_name\n",
    "y_pos = np.arange(len(name))\n",
    "performance = np.array(classifier_accuracy)\n",
    "performance=(performance*100)\n",
    "tick_label=performance.astype('str')\n",
    "ax.barh(y_pos, performance, align='center',\n",
    "        color='green', ecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(name)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_title('Accuracy Chart')\n",
    "ax.set_xticks([0,10,20,30,40,50,60,70,80,90,100])\n",
    "for i in range(len(name)):\n",
    "    ax.annotate(tick_label[i]+'%',xy=(int(performance[i]-10), i))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
